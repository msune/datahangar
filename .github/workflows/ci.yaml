name: ci

on:
  push:
  pull_request:
  schedule:
    - cron: '0 0 * * *'  # every day at midnight

jobs:
  cache-docker-images:
    runs-on: ubuntu-22.04
    steps:
      - name: Checkout datahangar
        uses: actions/checkout@v4
        with:
          path: datahangar

      - name: test
        uses: ./datahangar/.github/workflows/test.yaml
        with:
          ref: ${{ github.sha }}

  basic-test:
    needs: [cache-docker-images]
    runs-on: ubuntu-22.04
    strategy:
      fail-fast: false
      matrix:
        k8s_version: [v1.27.13, v1.28.9, v1.29.4]
        db: [druid, clickhouse]
    env:
      KCTL: "minikube kubectl -- "
      N_RECORDS: 1024
    steps:
      - name: Cleanup disk to maximize runner disk space
        uses: AdityaGarg8/remove-unwanted-software@v3 #easimon/maximize-build-space@v10
        with:
          remove-android: true
          remove-dotnet: True
          remove-haskell: true
          remove-codeql: true
          remove-docker-images: true

      - name: Checkout datahangar
        uses: actions/checkout@v4
        with:
          path: datahangar

      - name: Install dependencies
        run: |
          apt-get update && apt-get install -y jq
          pip install -r datahangar/tools/requirements.txt

      - name: "Start minikube - K8s ${{matrix.k8s_version}}"
        id: minikube
        uses: medyagh/setup-minikube@latest
        with:
          kubernetes-version: ${{matrix.k8s_version}}
          cpus: 'max'
          memory: 12G

      - name: Restore Docker images
        uses: actions/cache@v3
        with:
          path: /tmp/.docker
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-

      - name: Import docker cached images to minikube's registry
        run: |
          eval $(minikube docker-env)
          docker load -i /tmp/.docker/docker_images.tar
          docker image ls

      - name: "Deploy DataHangar stack (DB: ${{matrix.db}})"
        run: |
          cd /home/runner/work/datahangar/datahangar/datahangar
          rm stack/overlays/dev/storage/db
          ln -sf ${{matrix.db}} stack/overlays/dev/storage/db
          ls -la stack/overlays/dev/storage
          tools/dhctl.py -v deploy dev

      - name: Check health status of the DataHangar stack
        uses: nick-fields/retry@v3
        with:
          timeout_minutes: 5
          max_attempts: 40
          retry_wait_seconds: 15
          shell: bash
          command: /home/runner/work/datahangar/datahangar/datahangar/tools/dhctl.py status dev -p /home/runner/work/datahangar/datahangar/datahangar/

      - name: Inject 1024 netflow records
        run: |
          minikube kubectl -- apply -f /home/runner/work/datahangar/datahangar/datahangar/.github/workflows/files/job-inject-netflow.yaml

      - name: Launch count rows in TS DB job
        run: |
          minikube kubectl -- apply -f /home/runner/work/datahangar/datahangar/datahangar/.github/workflows/files/count-db-records.yaml

      - name: Launch check datacubes in Turnilo job
        run: |
          #Web ui is only supported with Druid DB
          if [[ "${{matrix.db}}" == "druid" ]]; then
            minikube kubectl -- apply -f /home/runner/work/datahangar/datahangar/datahangar/.github/workflows/files/turnilo-check-datacube.yaml
          fi

      - name: Check that number of rows in TS_DB matches injected traffic
        uses: nick-fields/retry@v3
        with:
          timeout_minutes: 3
          max_attempts: 40
          retry_wait_seconds: 15
          shell: bash
          command: /home/runner/work/datahangar/datahangar/datahangar/tools/dhctl.py status dev -p /home/runner/work/datahangar/datahangar/datahangar/

      - name: Show available disk space...
        run: |
          df -h
